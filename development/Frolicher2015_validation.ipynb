{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat budget validation\n",
    "\n",
    "I'm doing an analysis of the CMIP5 single forcing experiments (historicalGHG and historicalAA) to explore the separate influence of anthropogenic aerosols (AAs) and greenhouse gases (GHGs) on historical ocean change.\n",
    "\n",
    "To make sure that my heat budget calculations are correct, I'm first trying to reproduce the heat uptake values in Table 2 of [Frolicher et al (2015)](https://journals.ametsoc.org/doi/abs/10.1175/JCLI-D-14-00117.1). In particular, the following is my attempt to reproduce the heat uptake south of 30S for the GISS-E2-R model.\n",
    "\n",
    "In summary, the steps I take to calculcate the cumulative oceanic heat uptake south of 30S between 1870 (1861-80) and 1995 (1986-2005) are as follows:\n",
    "1. Load the monthly timescale hfds (surface downward heat flux) data for the region south of 30S\n",
    "2. Convert the units from $W m^{-2}$ to $J m^{-2}$ by multiplying by the number of seconds in each timestep\n",
    "3. Convert to an annual timescale by *summing* the 12 monthly values for each year\n",
    "4. Convert the units from $J m^{-2}$ to $J$ by multiplying each value by the corresponding grid-cell area\n",
    "5. Calculate the spatial sum (i.e. collapse the latitude and longitude dimensions)\n",
    "6. Calculate the 20-year *sum* for the time periods of interest\n",
    "7. Calculate the final result\n",
    "\n",
    "My result differs from Frolicher et al (2015) by a factor of 3. I haven't regridded the data to a $1 \\times 1$ grid like they did, but I doubt that explains such as discrepancy. I'm stumped as to what the issue could be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import numpy\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "from iris.experimental.equalise_cubes import equalise_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read data\n",
    "\n",
    "The code below simply loads all data south of 30S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat_constraint = iris.Constraint(latitude=lambda cell: cell <= -30)\n",
    "\n",
    "def read_hfds_data(file_list, lat_constraint):\n",
    "    \"\"\"Read in data for a given latitude constraint\"\"\"\n",
    "    \n",
    "    cube = iris.load(file_list, 'surface_downward_heat_flux_in_sea_water' & lat_constraint)\n",
    "    \n",
    "    equalise_attributes(cube)\n",
    "    iris.util.unify_time_units(cube)\n",
    "    cube = cube.concatenate_cube()\n",
    "    \n",
    "    return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iris 'Cube' of surface_downward_heat_flux_in_sea_water / (W m-2) (time: 10200; latitude: 61; longitude: 288)>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfds_control_files = glob.glob('/g/data/ua6/DRSv2/CMIP5/GISS-E2-R/piControl/mon/ocean/r1i1p1/hfds/latest/hfds_Omon_GISS-E2-R_piControl_r1i1p1_*.nc')\n",
    "hfds_control_cube = read_hfds_data(hfds_control_files, lat_constraint)\n",
    "\n",
    "hfds_control_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iris 'Cube' of surface_downward_heat_flux_in_sea_water / (W m-2) (time: 1872; latitude: 61; longitude: 288)>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfds_historical_files = glob.glob('/g/data/ua6/DRSv2/CMIP5/GISS-E2-R/historical/mon/ocean/r1i1p1/hfds/latest/hfds_Omon_GISS-E2-R_historical_r1i1p1_*.nc')\n",
    "hfds_historical_cube = read_hfds_data(hfds_historical_files, lat_constraint)\n",
    "\n",
    "hfds_historical_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Convert from W m-2 to J m-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def broadcast_array(array, axis_index, shape):\n",
    "    \"\"\"Broadcast an array to a target shape.\n",
    "    \n",
    "    Args:\n",
    "      array (numpy.ndarray)\n",
    "      axis_index (int or tuple): Postion in the target shape that the \n",
    "        axis/axes of the array corresponds to\n",
    "          e.g. if array corresponds to (depth, lat, lon) in (time, depth, lat, lon)\n",
    "          then axis_index = [1, 3]\n",
    "          e.g. if array corresponds to (lat) in (time, depth, lat, lon)\n",
    "          then axis_index = 2\n",
    "      shape (tuple): shape to broadcast to\n",
    "      \n",
    "    For a one dimensional array, make start_axis_index = end_axis_index\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if type(axis_index) in [float, int]:\n",
    "        start_axis_index = end_axis_index = axis_index\n",
    "    else:\n",
    "        assert len(axis_index) == 2\n",
    "        start_axis_index, end_axis_index = axis_index\n",
    "    \n",
    "    dim = start_axis_index - 1\n",
    "    while dim >= 0:\n",
    "        array = array[numpy.newaxis, ...]\n",
    "        array = numpy.repeat(array, shape[dim], axis=0)\n",
    "        dim = dim - 1\n",
    "    \n",
    "    dim = end_axis_index + 1\n",
    "    while dim < len(shape):    \n",
    "        array = array[..., numpy.newaxis]\n",
    "        array = numpy.repeat(array, shape[dim], axis=-1)\n",
    "        dim = dim + 1\n",
    "\n",
    "    return array\n",
    "\n",
    "\n",
    "def convert_to_joules(cube):\n",
    "    \"\"\"Convert units to Joules\"\"\"\n",
    "\n",
    "    assert 'W' in str(cube.units)\n",
    "    assert 'days' in str(cube.coord('time').units)\n",
    "    \n",
    "    time_span_days = cube.coord('time').bounds[:, 1] - cube.coord('time').bounds[:, 0]\n",
    "    time_span_seconds = time_span_days * 60 * 60 * 24\n",
    "    \n",
    "    cube.data = cube.data * broadcast_array(time_span_seconds, 0, cube.shape)\n",
    "    cube.units = str(cube.units).replace('W', 'J')\n",
    "    \n",
    "    return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iris 'Cube' of surface_downward_heat_flux_in_sea_water / (J m-2) (time: 10200; latitude: 61; longitude: 288)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfds_control_cube = convert_to_joules(hfds_control_cube) \n",
    "\n",
    "hfds_control_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iris 'Cube' of surface_downward_heat_flux_in_sea_water / (J m-2) (time: 1872; latitude: 61; longitude: 288)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfds_historical_cube = convert_to_joules(hfds_historical_cube) \n",
    "\n",
    "hfds_historical_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate the annual sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annual_sum(cube):\n",
    "    \"\"\"Calculate the annual sum.\"\"\"\n",
    "\n",
    "    iris.coord_categorisation.add_year(cube, 'time')\n",
    "    cube = cube.aggregated_by(['year'], iris.analysis.SUM)\n",
    "\n",
    "    cube.remove_coord('year')\n",
    "\n",
    "    return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iris 'Cube' of surface_downward_heat_flux_in_sea_water / (J m-2) (time: 850; latitude: 61; longitude: 288)>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfds_control_cube = annual_sum(hfds_control_cube) \n",
    "\n",
    "hfds_control_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iris 'Cube' of surface_downward_heat_flux_in_sea_water / (J m-2) (time: 156; latitude: 61; longitude: 288)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfds_historical_cube = annual_sum(hfds_historical_cube) \n",
    "\n",
    "hfds_historical_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Convert from J m-2 to J (i.e. multiply by area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiply_by_area(cube, area_cube):\n",
    "    \"\"\"Multiply each cell of cube by its area.\"\"\" \n",
    "\n",
    "    area_data = broadcast_array(area_cube.data, [1, 2], cube.shape)\n",
    "    cube.data = cube.data * area_data\n",
    "    units = str(cube.units)\n",
    "    cube.units = units.replace('m-2', '')\n",
    "    \n",
    "    return cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iris 'Cube' of cell_area / (m2) (latitude: 61; longitude: 288)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_file = '/g/data/ua6/DRSv2/CMIP5/GISS-E2-R/piControl/fx/ocean/r0i0p0/areacello/latest/areacello_fx_GISS-E2-R_piControl_r0i0p0.nc'\n",
    "area_cube = iris.load_cube(area_file, 'cell_area' & lat_constraint)\n",
    "\n",
    "area_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iris 'Cube' of surface_downward_heat_flux_in_sea_water / (J) (time: 850; latitude: 61; longitude: 288)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfds_control_cube = multiply_by_area(hfds_control_cube, area_cube) \n",
    "\n",
    "hfds_control_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iris 'Cube' of surface_downward_heat_flux_in_sea_water / (J) (time: 156; latitude: 61; longitude: 288)>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfds_historical_cube = multiply_by_area(hfds_historical_cube, area_cube) \n",
    "\n",
    "hfds_historical_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Calculate the spatial sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iris 'Cube' of surface_downward_heat_flux_in_sea_water / (J) (time: 850)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfds_control_cube = hfds_control_cube.collapsed(['latitude', 'longitude'], iris.analysis.SUM)\n",
    "\n",
    "hfds_control_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<iris 'Cube' of surface_downward_heat_flux_in_sea_water / (J) (time: 156)>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfds_historical_cube = hfds_historical_cube.collapsed(['latitude', 'longitude'], iris.analysis.SUM)\n",
    "\n",
    "hfds_historical_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Calculate the 20-year sum for the time periods of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_time_constraint(time_list):\n",
    "    \"\"\"Get the time constraint used for subsetting an iris cube.\"\"\"\n",
    "    \n",
    "    start_date, end_date = time_list\n",
    "\n",
    "    date_pattern = '([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})'\n",
    "    assert re.search(date_pattern, start_date)\n",
    "    assert re.search(date_pattern, end_date)\n",
    "\n",
    "    start_year, start_month, start_day = start_date.split('-') \n",
    "    end_year, end_month, end_day = end_date.split('-')\n",
    "    time_constraint = iris.Constraint(time=lambda t: iris.time.PartialDateTime(year=int(start_year), month=int(start_month), day=int(start_day)) <= t.point <= iris.time.PartialDateTime(year=int(end_year), month=int(end_month), day=int(end_day)))\n",
    "\n",
    "    return time_constraint\n",
    "\n",
    "\n",
    "def get_control_time_constraint(control_cube, hist_cube, time_bounds):\n",
    "    \"\"\"Define the time constraints for the control data.\"\"\"\n",
    "\n",
    "    iris.coord_categorisation.add_year(control_cube, 'time')\n",
    "    iris.coord_categorisation.add_year(hist_cube, 'time')\n",
    "\n",
    "    branch_time = hist_cube.attributes['branch_time']\n",
    "    \n",
    "    index = 0\n",
    "    for bounds in control_cube.coord('time').bounds:\n",
    "        lower, upper = bounds\n",
    "        if lower <= branch_time < upper:\n",
    "            break\n",
    "        else:\n",
    "            index = index + 1\n",
    "\n",
    "    branch_year = control_cube.coord('year').points[index]\n",
    "    hist_start_year = hist_cube.coord('year').points[0]\n",
    "    start_gap = int(time_bounds[0].split('-')[0]) - hist_start_year\n",
    "    end_gap = int(time_bounds[1].split('-')[0]) - hist_start_year\n",
    "\n",
    "    control_start_year = branch_year + start_gap\n",
    "    control_end_year = branch_year + end_gap\n",
    "\n",
    "    control_start_date = str(control_start_year).zfill(4)+'-01-01'\n",
    "    control_end_date = str(control_end_year).zfill(4)+'-01-01'\n",
    "\n",
    "    time_constraint = get_time_constraint([control_start_date, control_end_date])\n",
    "\n",
    "    control_cube.remove_coord('year')\n",
    "    hist_cube.remove_coord('year')\n",
    "\n",
    "    return time_constraint\n",
    "\n",
    "\n",
    "def temporal_sum(cube, time_constraint):\n",
    "    \"\"\"Calculate temporal sum over a given time period.\"\"\"\n",
    "\n",
    "    cube = cube.copy()\n",
    "    temporal_subset = cube.extract(time_constraint)\n",
    "    result = temporal_subset.collapsed('time', iris.analysis.SUM)\n",
    "\n",
    "    return float(result.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "period_1870 = ['1861-01-01', '1880-12-31']\n",
    "period_1995 = ['1986-01-01', '2005-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "historial, 1870:  -4.364972830864836e+22 J\n",
      "historial, 1995:  1.03512516942117e+23 J\n"
     ]
    }
   ],
   "source": [
    "hist_1870_constraint = get_time_constraint(period_1870)\n",
    "hist_1995_constraint = get_time_constraint(period_1995)\n",
    "\n",
    "hist_1870 = temporal_sum(hfds_historical_cube, hist_1870_constraint)\n",
    "hist_1995 = temporal_sum(hfds_historical_cube, hist_1995_constraint)\n",
    "\n",
    "print('historial, 1870: ', hist_1870, 'J')\n",
    "print('historial, 1995: ', hist_1995, 'J')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control, 1870:  -8.273873718425841e+22 J\n",
      "control, 1995:  -5.8289960161959945e+22 J\n"
     ]
    }
   ],
   "source": [
    "control_1870_constraint = get_control_time_constraint(hfds_control_cube, hfds_historical_cube, period_1870)\n",
    "control_1995_constraint = get_control_time_constraint(hfds_control_cube, hfds_historical_cube, period_1995)\n",
    "\n",
    "control_1870 = temporal_sum(hfds_control_cube, control_1870_constraint)\n",
    "control_1995 = temporal_sum(hfds_control_cube, control_1995_constraint)\n",
    "\n",
    "print('control, 1870: ', control_1870, 'J')\n",
    "print('control, 1995: ', control_1995, 'J')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative oceanic heat uptake south of 30S between 1870 (1861-80) and 1995 (1986-2005): 1.2271346822846692e+23\n"
     ]
    }
   ],
   "source": [
    "change = (hist_1995 - hist_1870) - (control_1995 - control_1870)\n",
    "print('Cumulative oceanic heat uptake south of 30S between 1870 (1861-80) and 1995 (1986-2005):', change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result provided by Frolicher et al (2015) is $3.6 \\times 10^{23} J$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
